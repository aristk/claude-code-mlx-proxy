# Claude Code MLX Proxy Configuration

# === Server Settings ===
HOST=0.0.0.0
PORT=8888

# === Model Settings ===
# Local path to downloaded model (via aria2) or HuggingFace model ID
MODEL_NAME=/tmp/deepseek-r1-7b-4bit

# Trust remote code (required for some models like GLM)
TRUST_REMOTE_CODE=false

# EOS token to strip from output (model-specific)
# DeepSeek R1: <|im_end|>
# Qwen: <|im_end|>
# GLM: (leave empty)
EOS_TOKEN=<|im_end|>

# === Generation Settings ===
DEFAULT_MAX_TOKENS=4096
DEFAULT_TEMPERATURE=1.0
DEFAULT_TOP_P=1.0

# === API Settings ===
# Model name exposed to Claude Code (must match expected model)
API_MODEL_NAME=claude-sonnet-4-5-20250929

# === Logging ===
# Enable verbose output for debugging
VERBOSE=false

# === Thinking/Reasoning ===
# Disable thinking mode support (prevents extraction of <think> blocks)
DISABLE_THINKING=false